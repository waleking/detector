\def\year{2017}\relax
\documentclass{article}
\usepackage{aaai17}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}

\usepackage{comment}
\usepackage{subfigure}
\usepackage{enumitem}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{algorithmic}

\usepackage{bm}%used for bm
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{amsmath} %used for maths symbols
\usepackage{amssymb}%used for empty set symbol
\usepackage{url}
\usepackage{xcolor}% or package color

\usepackage{makecell}


\usepackage{multirow}% for table

\newtheorem{rmk}{Definition}% definition

%used for quotes
\usepackage{epigraph}
\setlength\epigraphwidth{\columnwidth}
\setlength\epigraphrule{0pt}

\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\setcounter{secnumdepth}{2}  
 \begin{document}
% The file aaai.sty is the style file for AAAI Press 
% proceedings, working notes, and technical reports.
%
\title{Lightweight Transfer Learning from Knowledge Base to Microblog Stream for Accurate Event Detection}
\maketitle


%主动感知的
%\title{Is That Enough to Use the Recent Data to Detect Events?}
%\title{Revealing the Important Factors on the High Accuracy Event Detection}

%基于历史的 adoptable continous learning 连续学习for high accuracy event detection
%长轴：military方面的，三个切片，每个切片top10的词都进行展示。起始是维基的导入，连续学习产生了一个长轴。
%关注于重要事件的积累：1，变化很大，2，相当长的稳定性。长轴上的例子，第三个切片需要第一个切片的知识。第三个切片自身产生的很准确。
%两个例子：（1）之前学习的结果对事件检测有帮助（类似于张学良的case）；（2）可以扩展词表时新性很好，很准确；

%点明factor是什么——能准确描述历史知识的model，该model的表述能力起码能够model概念和概念之间的联系；model应该有一个实时自学习功能，即在历史知识的基础上，能在不断到来的新数据流上更新自己的知识。（“支持”恐怖组织，“打击”恐怖组织）打击恐怖组织的topic中，通常是美国和英国、法国；但是俄罗斯突然出现在该topic的列表中，说明俄罗斯参与打击恐怖组织应该被判别为一个新的事件。需要一个精确描述历史数据中概念之间联系的例子——（找到一个立场发生变化的例子，如果能在叙利亚问题上找到很好，如果不能考虑别的例子）。

\begin{abstract}
Many web applications need the real time event detection technique. But the accuracy of existing methods are still far from meeting the application requirements. 
%should be met, 这个词应该被强化，vital
We reaveal that the two important factors should be met, (1) having a good mechanism to organize the history data, and (2) having the capability of self-updating, to accumlate the knowledge about what is happening.
According to this guideline, we propose a knowledge base enhanced continous learning method for high accuracy event detection. 
In this proposed method, 1) the data structure\textit{history states} can be initialized by knowledge base to restore what happened; 2) \textit{recent states} are updated by \textit{history states} and upcoming text streams via our proposed probabilistic model HS-Prior-LDA to maintain what is happening; 3) events can be detected by recent states with high accuracy; 4) the \textit{history status} is 
Experiments on the benchmark \textit{Edinburgh twitter corpus (30 million tweets)} validate the effectiveness of our proposed \textsc{NSDetector}.
\textsc{NSDetector} promotes the accuracy rate by 9\% without  sacrificing the recall rate.
%在不牺牲召回率的情况下，将准确率相比于state-of-art提升了9%。


\begin{comment}
Event detection is an important task to understand what already happened and what is currently happening in the rapid evolving text stream. 
% what happened不需要了
% 诸多互联网的应用都迫切需要实时准确的事件检测技术。
% 由于需要实时监测最新发生的事件，人们通常实时分析最新的数据流来检测可能发生的事件，但很遗憾这种技术的准确率远远不能支撑应用的要求。

%举例之后,1这个例子说明需要哪些新技术支持——需要对历史知识有准确的描述，充分体现概念与概念之间的联系；并且能够利用新数据来更新相应的知识，以解决知识库的更新滞后于新数据的问题 2 列举related works，这些技术无法解决这个问题
%我们的工作。

%在Related Works 之前说明我们这是一个amazing的工作，同时将precision和recall都进行了提升，而一般的工作很难兼顾这一点。
But existing methods cannot achieve high precision and high recall simultaneously. 
The reason lies in that they only use the recent data and lack the accumulation of history knowledge. 
We further find out that the ideal event detection method should have two properties: \textit{organizing history data well} and \textit{self-updating}.
According to this guideline, we propose \textsc{NSDetector}, a high accuracy event detection method that trains normal states better by using knowledge base, which can be treated as the accumulation of history data. 
In \textsc{NSDetector}, 1) a new data structure \textit{normal states} is proposed to restore what happened; 2) \textit{normal states} can be initialized by knowledge base and further updated by upcoming text streams via our proposed probabilistic model NS-Prior-LDA; 3) events can be detected by normal states with high accuracy.
Experiments on the benchmark \textit{Edinburgh twitter corpus (30 million tweets)} validate the effectiveness of our proposed \textsc{NSDetector}.
\end{comment}
\end{abstract}

\section{Introduction}
Many web applications need the accurate event detection technique on microblog stream, such as public opinion analysis\cite{thelwall2011sentiment}, public security\cite{Li:2012gw}, and disaster response\cite{Yin:2012ht}, etc.
Although event detection has been a research topic for a long while\cite{allan1998topic}, event detection in microblog stream is still challenging\cite{atefeh2015survey}.
According to \cite{huang2016probabilistic}, the characteristics of microblog, which is fast changing, high noise, and short length, raise the challenge.

Knowledge base can be a good supplementary for event detection on microblog stream.
Different from the not-well-organized microblog stream, knowledge base (e.g. Wikipedia) is constructed elaborately and contains rich information. 
For example, the microblog message ``libyan rebel chief gunned down in Benghazi (2011-07-28)'' is short, but still comprehensible because the words ``\textit{libyan}", ``\textit{Benghazi}'' are included in the wiki page ``\textit{Libya}", and the words ``\textit{rebel}'', ``\textit{gun}'' appeared in the wiki page ``\textit{Military}''.
By reading these two wiki pages, readers easily understand the example tweet is talking about something related to \textit{Military} and \textit{Libya}.
In other words, knowledge base enrichs the linkage
Since transfer learning aims at , it provides a way to .

But it's non-trivial to perform transfer learning directly from knowledge base to microblog stream.

Nowadays knowledge base and text stream are two important channels for people to gain information. 
Usually people learn the facts from knowledge base (e.g. Wikipedia), and get informed the bursty events from text stream (e.g. Twitter).

Existing event detection methods meet the challenges caused by characteristics of the not-well-organized text stream.
Firstly, the posts in the text stream particular diverse.
Second, the posts are noisy. 
These problems can be cut down by incorporating knowledge base. 

But the transfer learning from knowledge base to text stream for is non-trivial.
RDF is expensive to apply to the text stream directly.
What the most close method Twevent is designed for pos-precessing rather than incorporating them together.

To handle this challenge, we propose a lightweight transfer learning method, specialized for event detection task. 
There are two designed data structure to balance the performance and cost.  
\textit{History states} are. 
\textit{Recent states} are.

\begin{comment}
Many web applications\cite{ge2015bring}\cite{hughes2009twitter}\cite{sakaki2010earthquake} need the real time event detection technique. 
But the accuracy of existing methods are still far from meeting the application requirements. 
The main stream of existing methods focus on monitoring the changes of the recent data\cite{Allan:2000wu}\cite{Petrovic:2010uj}\cite{Wurzer:2015wq}, and some others use the history data by word frequencies\cite{Li2013JointEE}\cite{Nguyen2015EventDA} and dictionary\cite{Twevent2012}. 
A typical example the existing methods cannot handle well is that ``Russia's anti-ISIS operation in Syria". The word Russia, ISIS, and Syria are trivial, while Russia's anti ISIS is nontrivial because US and other Europe countries but not Russia are the countries that anti ISIS  before September 2015. 
%这个例子应该

To handle this challenge, the important factors on the high accuracy event detection are needed: (1) having a good mechanism to organize the history data, and being aware of what happened; (2) having the capability of self-updating, to accumlate the knowledge about what is happening.
\end{comment}

The properties of the ideal event detection method also coincide with the news value theory\cite{galtung1965structure}\cite{caple2013delving}, which emphasizes the \textit{news unexpectedness} -- ``the unpredictable or the rare is more newsworthy than the routine"\cite{bell1991language}.
Following this guideline, if the journalist knew the normal states, aka, the ``routine things" of everyday better, he/she would tend to choose more unexpected news to report. 
We suppose that the ideal event detection system performs like a journalist who can find news from cyberspace with the knowledge of the normal states. 

It's very close for the ideal event detection method, which holds the previous mentioned two properties (\textit{organizing history data well} and \textit{self-updating}). To implement the ideal event detection method, we propose \textsc{NSDetector}, a high accuracy event detection method that trains normal states better by using knowledge base, which can be treated as the accumulation of happened things. 
In \textsc{NSDetector}, 1) a new data structure \textit{normal states} is proposed to restore what happened; 2) \textit{normal states} can be initialized by knowledge base and further updated by upcoming text streams via our proposed probabilistic model NS-Prior-LDA; 3) events can be detected by normal states with high accuracy.

\begin{comment}
But the existing computation on the RDF graph is often time consuming. To overcome this obtacle, we propose the new data structure \textit{normal states}, which not only utilize the structure adequately but also maintain the information about what happened and what's happening more efficiently than RDF.  
\end{comment}

\begin{figure}[h]
    \centering
    \includegraphics[width=.82\columnwidth]{img/NSDetectorExample.pdf}
    \caption{\textsc{LTDetector}'s process flow, taking \textit{Military} related events in cyberspace as an example. \textsc{LTDetector} initializes the normal states about military from knowledge base, learns the topical words further within the time windows on the target corpus, detects events, and updates the normal states incrementally by the detected events.}
    \label{fig:modelDesc}
\end{figure}


The contribution of this paper is mainly in three aspects.
(1) We reveal that there are two important factors for high accuracy event detection-- a comprehensive model that can organize history data well, and updating the model well.
(2) We propose the probability model \textsc{NSDetector}. 
The model can combine the history data and the recent data, further determine the arrival new document whether it represents a new event. 
More than that, \textsc{NSDetector} has the capability to update the knowledge of what happend.
(3) The experiment on the Edinburgh twitter corpus which contains 30 million tweets show that \textsc{NSDetector} promotes the accuracy rate by 9\% without sacrificing the recall rate.


\section{Related Works}
The first category of methods, including UMass\cite{Allan:2000wu} and BurstyBTM\cite{Yan:2015wm}, use \textit{the data within the recent time windows} to help to decide whether the incoming article is related to a new event. 
This kind methods can be implemented by clustering of articles\cite{Allan:2000wu}\cite{Petrovic:2010uj}\cite{Wurzer:2015wq}, word frequencies\cite{Mathioudakis:2010fc}\cite{Weng:2011wz}, or topic modeling\cite{Diao:2012wj}\cite{Yan:2015wm} in the recent time windows. 
Taking the clustering of articles as an example, they model the occurred events as clusters, and link the incoming article with an already existed event cluster or assign it as the new detected event.
The decision is based on whether the dissimilarity between the incoming article and existed event clusters is over the user-specified threshold. 

The reason why this kind methods cannot achive high precision and high recall simultaneously lies in that they lack the accumulation of history knowledge. 
This kind methods ``understand" the document only by the recent data and the frequencies of the data, but the ``understanding" is not so confident that they still need the specific threshold to help to make decision. In the journalist metaphor of news value theory, they have the limited knowledge of normal states (aka "routine things") due to the limited history information used. 
On the one hand, UMass\cite{Allan:2000wu} prefers the lower threshold to enlarge the recall but suffers the precision. 
On the other hand, BurstyBTM needs the appropriate number of topics to run the topic modelling, and detects the ``large" events that associate with many articles but ignores the ``small" ones. 

The second category of methods thouroughly relies on the \textit{history data}. 
The typical implementation is to train the event triggers\cite{Li2013JointEE}\cite{Nguyen2015EventDA} from history labeled data, then apply the trained model to detect the event related articles, which contain the triggers such as the word \textit{attacked} for the \textit{public security} events. 
This kind methods suffer from the loss of recall. 
There are two reasons. 
%没有对历史数据进行很好的组织
(1) The model does not utilize the history data sufficiently. 
Usually, the event trigger based method mainly focus on the event related verbs, but often ignores the other word types.
(2) The model lacks the update mechanism. 
It only restores the history knowledge but without updating. 
Some new event related articles may be mistakenly filtered out because not containing previous trained triggers. 
For example, the tweet ``Russia's intervention in Syria began in September 2015" without an event trigger, which is really related to a \textit{public security} event, may be omitted by the system. 



Although \cite{Wurzer:2015wq} points out that UMass\cite{Allan:2000wu} and its variants\cite{Petrovic:2010uj}\cite{petrovic2012using}\cite{Wurzer:2015wq} are the state-of-art systems on the Event Detection task for the newswire data, these systems still suffers from the lack of accuracy to applied on more general cyberspace data, such as tweets, emails, and reddit posts. 
The underlying reason is that the normalized Topic Weighted Minimum Cost metric (\(C_{min}\)) used in the Event Detection keep balance between miss and false alarm, which cannot work well on the .
Usually these traditional systems set the ratio of cost between miss alarm and false alarm to 10, preferring recall to precision on detecting events.

%\textbf{Knowledge Base}. \cite{faralli2015large} propose the Twixonomy Graph. 


%Twitter Trending Topic Classification
%We use PageRank-HITS\cite{Yan:2015wq} algorithm to update score of categories in wikipedia.

%3*4 figures, 0-11 is reorganized in the following order: 0, 1, 4, 5, 8, 9;
%2, 3, 6, 7, 10, 11;
\begin{comment}
\begin{figure*}[ht]
        \centering
        \label{fig:subfig} %% label for entire figure
        \subfigure[\((0.25,0.25,0.25)\)]{
                \label{fig:subfig:a} %% label for first subfigure a
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph0.pdf}
        }
        \subfigure[\((0.5,0.5,0.5)\)]{
                \label{fig:subfig:b} %% label for second subfigure b
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph1.pdf}
        } 
        \subfigure[\((0.25,0.25,0.75)\)]{
                \label{fig:subfig:c} %% label for third subfigure c
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph4.pdf}
        }
        \subfigure[\((0.5,0.5,1.5)\)]{
                \label{fig:subfig:a} %% label for first subfigure d
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph5.pdf}
        }
        \subfigure[\((0.25,0.75,0.75)\)]{
                \label{fig:subfig:d} %% label for third subfigure e
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph8.pdf}
        }
        \subfigure[\((0.5,1.5,1.5)\)]{
                \label{fig:subfig:d} %% label for third subfigure f
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph9.pdf}
        }\hspace{1in}
        \subfigure[\((1.5,1.5,1.5)\)]{
                \label{fig:subfig:d} %% label for third subfigure g
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph2.pdf}
        }
        \subfigure[\((2.5,2.5,2.5)\)]{
                \label{fig:subfig:a} %% label for first subfigure h
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph3.pdf}
        }
        \subfigure[\((1.5,1.5,2.5)\)]{
                \label{fig:subfig:d} %% label for third subfigure i
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph6.pdf}
        }
        \subfigure[\((2.5,2.5,3.5)\)]{
                \label{fig:subfig:d} %% label for third subfigure j
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph7.pdf}
        }
        \subfigure[\((1.5,2.5,2.5)\)]{
                \label{fig:subfig:d} %% label for third subfigure k
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph10.pdf}
        }
        \subfigure[\((2.5,3.5,3.5)\)]{
                \label{fig:subfig:a} %% label for first subfigure l
                \includegraphics[height=2.14cm]{img/croppedDirichletGraph11.pdf}
        }\hspace{1in}
        \caption{Illustration of Dirichlet distribution's probabilistic density on the 3-dimensional simplex when given different priors. (a,b,g,h) the left four subfigures illustrate the probabilistic density when given the symetric priors for Dirichlet distribution; (c,d,i,j) the central subfigures illustrate the probablistic density given ; (e,f,k,l) }
\end{figure*}
\end{comment}


\section{Proposed Method}
Knowledge base often contains much information about what happened. 
But the exisiting RDF model\cite{klyne2006rdf} on knowledge base lacks the mechanism to maintain the information about what's happening, especially when applied on text stream.  
With the help of knowledge base's structure (detailed in sec \ref{subsec:hs_initialization}), we provide a  lightweight model to transfer the information in knowledge base to text stream.

\textit{History state} is the proposed data structure to restore the information about what happened. 
Initially, \textit{history state} extracts category-related history data into a set of tuples, which weighs the importance of given words to the specific category, defined in Definition 1 formally. 
Taking the \textit{military} category in Figure \ref{fig:modelDesc} as an example, the history state of \textit{military} contain the words \textit{army}, \textit{military}, and \textit{shootings} etc. 

\textit{Recent state} is the proposed data structure to maintain the information about what's happening.
It extracts category-related words from incoming text stream, for each time window.
Still taking the \textit{military} category in  Figure \ref{fig:modelDesc} as an example, based on extracted history states, our proposed probabilistic continuous learning model \textsc{HS-Prior-LDA} can recognize the words \textit{libyan} and \textit{rebel} in the time window 2011-07-28 in the text stream are related to the category \textit{military}. 
Furthermore the time series analysis on the neighboring recent states can recognize the set of events' candidate words, and finally detects the events in the text stream. 
In the example of Figure \ref{fig:modelDesc}, the words \textit{libyan} and \textit{rebel} are related to the \textit{military} event ``\#libya Libyan rebels chief is killed (2011-07-28)''.

After processing each time window's data, the history states can be incrementally updated by the recent state. 
In this way, the proposed model utilizes the rich history data in knowledge base, and performes continous learning on the incoming text stream, which can promote the accuracy of event detection significantly. 
The followings definitions are the concepts used by the continous learning model \textsc{HS-Detector}. 


\begin{rmk}[History State] 
The history state of the specific category is defined by a set of tuples, in which the first element is the word \(w^{(c)}_i\) related to the category \(c\), and the second element is the chi-square score \(chi(c,w^{(c)}_{i})\) under the category \(c\). 
And we denote the history states of category \(c\) as \(\bm{h}_c=\{<w^{(c)}_i,chi(c,w^{(c)}_{i})>\}_{i=1,...,N_c}\).
\end{rmk}

\begin{rmk}[Recent State] 
The recent state at time \(t\) of the specific category \(c\) is defined by a set of tuples, and detenoted as \(\bm{r}_{c,t}=\{<w^{(c)}_i,n(c,t,w^{(c)}_{i})>\}_{i=1,...,N_c}\), in which word \(w^{(c)}_{i}\) is related to the category \(c\), and \(n(c,t,w^{(c)}_{i})\) is its document frequency in the time window \(t\).
\end{rmk}


Section \ref{subsec:hs_initialization} explains the details of how to initialize history states from knowledge base.
Section \ref{subsec:rs_initialization} shows how to perform transfer learning for recent states.
And section \ref{subsec:detection} interprets the high accuracy event detection based on the processed recent states.
\begin{comment}
\begin{table}
\scriptsize
\caption{Notations used by \textsc{NSDetector}}
\label{tbl:notations}
\begin{tabular}{|c|p{0.06\columnwidth}|p{0.66\columnwidth}|} \hline
%first part: normalization initialization
\multirow{5}{0.13\columnwidth}{History States' Initialization} & \(G^{(0)}\) & Taxonomy's Graph in Knowledge Base\\ \cline{2-3}
& \(G^{(1)}\) & Category-Page Bipartite Graph in Knowledge Base\\ \cline{2-3}
& \(G^{(2)}\) & Page-Content Map in Knowledge Base\\ \cline{2-3}
& \(c\) & topic related category node in \(G^{(0)}\), \(G^{(1)}\) \\ \cline{2-3}
& \(K_{\bm{KB}}\) & number of pre-defined topics in Knowledge Base \\ \cline{2-3}
& \(h_{c,w}\) & word \(w\)'s history state (chi-square score) in category \(c\) \\ \hline
%second part: normalization maintenance
\multirow{4}{0.13\columnwidth}{Normal States Maintenance} & \(\lambda\) & normal state weight in  NS-Prior-LDA\\ \cline{2-3}
& \(\tau_{c,w}\) & word \(w\)'s prior knowledge confidence for topic \(c\) in NS-Prior-LDA\\ \cline{2-3}
& \(S_c\) & topic \(c\)'s all normal states related words \\ \cline{2-3}
& \(K\) & number of topics in NS-Prior-LDA such as \(K>K_{\bm{KB}}\)\\ \hline
%third part: event detection
\multirow{5}{0.13\columnwidth}{Event Detection} & \(\mathcal{B}_{c, t}\)  & event words set detected from topic \(c\) at time \(t\)  \\ \cline{2-3}
& \(\mathcal{G}_{c, t}\)  & hot word graph constructed from \(\mathcal{B}_{c, t}\) \\ \cline{2-3}
& \(\mathcal{C}_{c,t,i}\) & event \(i\)-th related words in topic \(c\) at time \(t\) \\ \cline{2-3}
& \(\mathcal{D}_{c,t,i}\) & event \(i\)-th related articles in topic \(c\) at time \(t\) \\ \cline{2-3}
& \(\rho\) & density threshold for the sub-graph constructed by event words  \\ \hline

\end{tabular}
\label{symbolsInModel}
\end{table}
\end{comment}


\subsection{History States Initialization}\label{subsec:hs_initialization}
In this part, we discuss in detail how to initialize the history states from the given knowledge base. 
The knowledge base such as Wikipedia has the structure of classes, subclasses, instances, and the edges between them. 
This structure usually can be represented as triples in RDF graph\cite{klyne2006rdf}, which is adopted to build DBPedia\cite{auer2007dbpedia} and YAGO\cite{suchanek2007yago} from Wikipedia. 
But the reasoning and maintainence of knowledge on the graph is usually expensive\cite{broekstra2003inferencing}\cite{bursztyn2015reasoning}. 
To make a trade-off between cost and performance, we use the lightweight data struture \textit{history state} to represent the knowledge about what happend, which is extracted from the knowledge base.
And the knowledge base's threefold structure \(G^{(0)}\), \(G^{(1)}\), \(G^{(2)}\) benefits the extraction of history states. 

\textbf{Taxonomy Graph \(G^{(0)}\)}. The directed edges in \(G^{(0)}\) represent the \textit{class}\(\rightarrow\)\textit{subclass} relations in the knowledge base. 
Taking Wikipedia for example (Figure \ref{fig:NSinitializaton}), the node \textit{Main topic classifications}\footnote{\url{https://en.wikipedia.org/wiki/Category:Main_topic_classifications}} has the subclass \textit{Society}, further contains the subclass \textit{Politics}, which is the ancestor of the subclass \textit{Military}.
As \(G^{(0)}\) is not a Directed Acyclic Graph originally\cite{faralli2015large}, we remove the cycles according to nodes' PageRank-HITS\cite{Yan:2015wq} score.
Specifically, the edges \textit{class}\(\rightarrow\)\textit{subclass} are preserved only when the node \textit{class} has the higher PageRank-HITS score than the node \textit{subclass}, which is shown in the line \ref{alg:line2inNormalStatesInit} of Algorithm \ref{alg:normalStatesInit}.
After removing cycles, the taxonomy structure on the knowledge base is better represented by the directed acyclic graph \(G^{(0)'}\).
As shown in line \ref{alg:line3inNormalStatesInit} of Algorithm \ref{alg:normalStatesInit}, by visiting the category \textit{Military} in the DAG \(G^{(0)'}\), the breadth-first traverse can reach its successor sub-category nodes such as \textit{Firearms}, \textit{The World Wars}, and \textit{World War II}, etc. 
\begin{figure}[h]
    \centering
    \includegraphics[width=.82\columnwidth]{img/initializationExample.pdf}  
    \caption{Illustration on how to initialize history states from Wikipedia, taking \textit{Military} as an example.}
    \label{fig:NSinitializaton}
\end{figure}

\textbf{Category-Page Bipartite Graph \(G^{(1)}\)}. 
The directed edges in \(G^{(1)}\) represent the \textit{class}\(\rightarrow\)\textit{instance} relations in the knowledge base.
In Wikipedia, by considering \(G^{(0)'}\) and \(G^{(1)}\) together as shown in line \ref{alg:line5inNormalStatesInit} of Algorithm \ref{alg:normalStatesInit}, we can get all the pages related to the given category. 

\textbf{Page-Content Map \(G^{(2)}\)}. 
For a specific Wikipedia dumps version, the edges \textit{page}\(\rightarrow\)\textit{content} in \(G^{(2)}\) define a one-to-one mapping.
There are a bulk of hisotry information restored in the wiki text content.
In order to extract the key words in wiki page's content, which distinguish it from other pages, we use the chi-square statistics\cite{yang1997comparative}\cite{liu2009imbalanced} to measure the importance of each word for the specific page.

For a given category in \(G^{(0)'}\), chi-square statistics also can evaluate the importance of each word appeared in text contents. 
For example, the chi-square statistic of the term \textit{shooting} under the category \textit{military} is 2888.7 which corresponds to the p-value 0.0001 of chi-square test with 1 degree of freedom.
That means the term \textit{shooting} is highly related to the category \textit{military}.  
To prevent the overclaim of rare word by chi-square statitistcs, the word frequency is introduced as a supplement\cite{liu2009imbalanced}, as shown in line \ref{alg:line10inNormalStatesInit} of Algorithm \ref{alg:normalStatesInit}.
Finally, we can get the category's history state, which are  composed by the category related words and their corresponding importance.
%history states衡量一个词在考虑完整历史信息的情况下，对于一个类别的重要程度，例如在military类别下面；从某种程度上讲，history state从knowledge base中抽取了对于该类别的重要特征，有助于我们将它应用到text stream当中。
\begin{algorithm}[h]
\scriptsize
\caption{History State Initialization from Knowledge Base}
\label{alg:normalStatesInit}

\KwIn{Taxonomy's Graph \(G^{(0)}\), Category-Page Bipartite Graph \(G^{(1)}\), Page-Content Bipartite Graph \(G^{(2)}\), topic related category node \(c\)}
\KwOut{History state \(\bm{h}_c\) on category \(c\)}
\(Pages(c)\leftarrow \varnothing\)\\
DAG \(G^{(0)'} \leftarrow\) Remove Cycles of \(G^{(0)}\) by nodes' HITS-PageRank scores. \label{alg:line2inNormalStatesInit}\\
\(SuccessorNodes(c) \leftarrow \) Breadth-first-traverse(\(G^{(0)'},c\))\label{alg:line3inNormalStatesInit}\\
\For{\(node \in SuccessorNodes(c)\)}{
    \(Pages(c) \leftarrow Pages(c) \cup G^{(1)}.neighbours(node)\) \label{alg:line5inNormalStatesInit}\\
}
Word frequency table \(n(c,.) \leftarrow \) do word count on the text contents of \(Pages(c)\) \\
Word frequency table \(n(All,.) \leftarrow \) do word count on the text contents of all pages in \(G^{(2)}\).\\
\For{word \(w\) in WordFrequencyTable(All).keys()}{
    \(chi(c,w) \leftarrow \) \(w\)'s chi-square statistics on \(WordFrequencyTable(c)\) and \(WordFrequencyTable(All)\).\\
    \(h_{c,w} \leftarrow n(c,w)*chi(c,w)\) \label{alg:line10inNormalStatesInit}\\
}
\Return{\(\bm{h}_c\)}
\end{algorithm}

Considering the full Wikipedia's contents, history state evaluates the importance of word to the concerned category accurately. 
For example, in \textit{Military}'s history state, the top  words are \textit{army}, \textit{military}, \textit{air}, \textit{command}, \textit{force}, and \textit{regiment}, etc. 
The document which contains these words is related to the category \textit{Military} with high probability. 
We further discuss how to apply history states to the text stream on the following subsection \ref{subsec:rs_initialization}.

\subsection{Recent States' Maintenance}
\label{subsec:rs_initialization}
In this subsection, we describe how the proposed probabilistic model \textsc{HS-Prior-LDA} utilizes the history states to learn the recent states from text stream.

There are two facts inspiring \textsc{HS-Prior-LDA}. 
(1) The topics in the document may contain history-state-like topics. 
As an example, the tweet ``Libyan rebel chief gunned down in Benghazi (2011-07-28)'' contains the topic that is similar to the \textit{Military}'s history state.
(2) The history-state-like topics can reuse the information  stored in the history states.
The word \textit{libyan} in the aforementioned example tweet ranks much higher in the \textit{Military} and the \textit{Middle East} history states than the other categories' history states.
After considering the relatedness between the remaining context and the history states, the learned topics of the example tweet include \textit{Military} and \textit{Middle East}. 

The generative process of \textsc{HS-Prior-LDA} can be described as follows.

\begin{enumerate}[itemsep=0mm]
\item Draw corpus prior distribution \(\bm{m} \sim Dir(\alpha \bm{u})\), where \(\bm{u}\) is the uniform distribution.
\item For each topic \(k \in \{1,\cdots,K\}\), 
\begin{enumerate}[itemsep=0mm]
\item word distribution on the topic \(\bm{\phi_k} \sim Dir(\bm{\beta}+ \bm{\tau_k})\).
\end{enumerate}
\item For each document index \(d \in \{1,\cdots,D\}\),
\begin{enumerate}[itemsep=0mm]
\item topic distribution on the document \(\theta_d \sim Dir(\bm{m})\),
\item for each word index \(n \in \{1,\cdots,N_d\}\),
\begin{enumerate}[itemsep=0mm]
\item word's topic assignment \(z_{dn} \sim Multinomial(\theta_d)\), 
\item word \(w_{dn} \sim Multinomial(\phi_{z_{dn}})\). 
\end{enumerate}
\end{enumerate}

\end{enumerate}

In the above generative process, the line 2(a) is the key point to distinguish \textsc{HS-Prior-LDA} from LDA\cite{blei2003latent}, where \(\bm{\tau}_k\) is defined by Equation(\ref{eq:wikiPrior}).
\(K_{KB}\) is the number of pre-defined history-state-like topics, and \(S_k\) is the set of words appeared in the \(k\)-th topic's history state.
As \cite{wallach2008structured} mentioned that the asymmetric prior distribution can significantly improve the quality of topic modelling, \(\bm{\phi_k} \sim Dir(\bm{\beta}+ \bm{\tau_k})\) incorporates history state into the asymmetric prior of the word distribution on topic. 
The effect of \(\bm{\tau_k}\) is obvious, e.g., \(\tau_{Military,army}/\tau_{Military,basketball}=203\) leads to that topic \textit{Military} prefers to contain the word \textit{army} other than \textit{basketball}.
The parameter \(\lambda\) controls how much the learned topics are similar to the history state, which can be chosen by cross-validated grid-search. 

\begin{scriptsize}
\begin{equation}
\label{eq:wikiPrior}
\begin{aligned}
\tau_{kv}=
\left\{ \begin{aligned}
\lambda \frac{h_{kv}}{\sum_{v\in S_{k}}h_{kv}} &,v\in S_{k}\ and  \ k \leq K_{\bm{KB}} \\
0&,v \notin S_{k} \ or \ k > K_{\bm{KB}} \\
\end{aligned}\right.
\end{aligned}
\end{equation}
\end{scriptsize}

\begin{comment}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.75\columnwidth]{model/lda_tikz.pdf}
    \caption{Probabilistic model for training normal states by using history information.}
    %The convolution neural network for extracting character-level representations of words. Dashed arrows indicate a dropout layer applied before character embeddings are input to CNN.}
    \label{fig:NS-Prior-LDA}
\end{figure}
\end{comment}
\begin{comment}
\ \ Our topic modeling, want to learn the first \(k\) topics with Wikipedia Article \(k\) topics as close as possible, and we will be Wikipedia article \(k\) before 1000 words) was added to the theme of the word frequency word in the subject a priori distribution on the.
Learning to be the first \(k\) Subject polynomial distribution of the word, referred to as \(\phi_k \), Wikipedia article \(k \) distribution of topics for \(\tau_k \), then this formalized process is expressed as: \(\ \phi_k \sim Dir(\beta + \tau_k) \).
Formal presentation of the explanation is: With prior knowledge \(\tau_k \) after the theme \(\phi_k \) is no longer simply rely on symmetric priori \(\beta \), different words right is not the same weight , such as a discussion of "fashion" theme in Wikipedia, it will refer to "dress", "grand", "blue", "gold" and other words, with the asymmetric priori \(\beta + \tau_k \) after in microblogging "fashion" theme "dress" the proportion will be increased in this way so that microblogging corpus theme tends to Wikipedia topic.
\(\tau_k \) in the first \(v \) words such as formula (\ref{eq:wikiPrior}).
Where \(S_k \) as a set of candidate words: high-quality information to use Wikipedia, we extract the theme \(\phi_k \ \) in the higher-word word frequency candidate set \(S_k \).
We can control set \(S_k \) in size, the size of the control is usually set for 1000.
The number of frequency \(n_{kv} \) for the word \(v \) (\ k) appears in the Wikipedia article themes.
If the word \(v \) does not appear in the candidate set \(S_k \), and then set a priori knowledge \(\tau_{kv} = 0 \), otherwise, the word frequency is proportional to \(n_{kv} \) with the prior knowledge of weight \(W\).
In the latter experiment, we will be on a priori knowledge of weights \(W \) will be discussed. 
\end{comment}

To solve \textsc{HS-Prior-LDA}, the gibbs sampling is adopted to determine the hidden variable \(z_{dn}\) and the model parameter \(\phi_k\).
In the initialization phase of gibbs sampling for \textsc{HS-Prior-LDA}, the hidden variable \(z_{dn}\) is initialized to topic \(k\) with probability \(\hat{q}_{k|v}\) as Equation (\ref{eq:initProbability}).
For the word \(v\) that belongs to any history state, \(\hat{q}_{k|v}\) is propotional to its importance in the history state \(\tau_{kv}\) as Eq\ref{eq:initProbability}(a). 
For the new word \(v\) in text stream, \(\hat{q}_{k|v}\) is   set uniformly \(1/(K-K_{\bm{KB}})\) on the other topics as Eq\ref{eq:initProbability}(b,c). 
The initialization makes sure that the learned topics are aligned to the pre-defined history states.
\begin{scriptsize} 
\begin{equation}
\label{eq:initProbability}
\begin{aligned}
\hat{q}_{k|v}=
\left\{ \begin{aligned}
\frac{\tau_{kv}}{\sum_{k=1}^{K}\tau_{kv}} &,\sum_{k}\tau_{kv}>0 & (a)\\
0&, \sum_{k}\tau_{kv}=0 \ and \ k \leq K_{\bm{KB}} & (b)\\
1/(K-K_{\bm{KB}})&,\sum_{k}\tau_{kv}=0 \ and \ k > K_{\bm{KB}} & (c)
\end{aligned}\right.
\end{aligned}
\end{equation}
\end{scriptsize}

%采样公式p(z|.)，z有两部分。
The sampling process uses the conditional probability \(p(z_{dn}=k|.)\propto (n^{(d)}_{dk}+\alpha m_k)(n^{(w)}_{kv}+\tau_{kv}+\beta)/(n^{(w)}_{k,.}+\tau_{k,.}+V\beta)\), where \(n^{(d)}_{dk}\) is the number of words in document \(d\) assigned to topic \(k\), and \(n^{(w)}_{kv}\) is the times of word \(v\) assigned to topic \(k\).
We also optimize \(\alpha \bm{m}\) for promoting \textsc{HS-Prior-LDA}'s fitting to documents according to \cite{wallach2008structured}\footnote{\url{https://github.com/mimno/Mallet/blob/master/src/cc/mallet/types/Dirichlet.java}}.\begin{comment}
\begin{equation}
\label{eq:KBPriorLDAgibbs}
\begin{aligned}
&p(z_{dn}=k|w_{dn}=v,z_{\neg{dn}},w_{\neg{dn}},\alpha\bm{m},\beta,\tau)\\
&\ \ \propto (n^{(d)}_{dk}+\alpha m_k)\frac{n^{(w)}_{kv}+\tau_{kv}+\beta}{n^{(w)}_{k,.}+\tau_{k,.}+V\beta}
\end{aligned}
\end{equation}
\end{comment}

\begin{comment}
\begin{scriptsize}
\begin{equation}
\label{eq:KBPriorLDAgibbs}
\begin{aligned}
&p(z_{dn}=k|w_{dn}=v,z_{\neg{dn}},w_{\neg{dn}},\alpha\bm{m},\beta,\tau)\\
&\ \ \propto (n^{(d)}_{dk}+\alpha m_k)\frac{n^{(w)}_{kv}+\tau_{kv}+\beta}{n^{(w)}_{k,.}+\tau_{k,.}+V\beta}
\end{aligned}
\end{equation}
\end{scriptsize}
\end{comment}

\begin{comment}
\begin{algorithm}
\scriptsize
\caption{NS-Prior-LDA Learning Algorithm}
\label{alg:gibbsSamplingKBPriorLDA}
\KwIn{Documents \(\mathcal{D}\) (a.k.a., \(\bm{w_{1:D}}\)), and normal states \(\bm{f}_{1:K_{\bm{KB}}}\)}
\KwOut{The sufficient statistics \(\bm{n^{(d)}}\), \(\bm{n^{(w)}}\)}
\tcc{Initialization of NS-Prior-LDA}
\For{\(d=1:D\)}{
    \For{\(n=1:N_d\)}{
        \(v=w_{dn}\), sample \(z_{dn}=k\) as Eq(\ref{eq:wikiPrior})(\ref{eq:initProbability}).\\
        Update the sufficient statistics \(n^{(d)}_{d,k}\), \(n^{(w)}_{k,v}\).\\
            }
        }
\For{\(i= 1:I\)}{
    \tcc{E-Step of NS-Prior-LDA}
    \For{\(i=1:I_E\)}{
        \For{\(d=1:D\)}{
            \For{\(n=1:N_d\)}{
                Set \(v=w_{dn}\), and reset the sufficient statistics \(n^{(d)}_{d,z_{dn}}\), \(n^{(w)}_{z_{dn},v}\).\\
                Resample \(z_{dn}=k\) as Eq(\ref{eq:wikiPrior})(\ref{eq:KBPriorLDAgibbs}).\\
                Update the sufficient statistics \(n^{(d)}_{d,k}\), \(n^{(w)}_{k,v}\).\\
            }
        }
    }
    \tcc{M-Step of NS-Prior-LDA}
    Optimize \(\alpha \bm{m}\) by the fixed-point iteration\cite{wallach2008structured}. 
}
\Return{\(\bm{n^{(w)}}\)}
\end{algorithm}
\end{comment}

After gibbs sampling on discrete time windows, \textsc{HS-Prior-LDA} learned all hidden topics of words.
And for a specific word type \(w\) and its history-state-like topic assignment \(c\) in time window \(t\), its document frequency is counted as \(n(c,t,w^{(c)})\), which is the element of category \(c\)'s \(t\)-th recent state.
Event detection on recent states is discussed in the following subsection.

\subsection{Detecting Events from Recent States}
\label{subsec:detection}
Text stream evolves more quickly with time than knowledge base.
For example, recent state of Military contain .
In other words, recent state is history-state-like topic timestamp.%在时间轴上的横截面。

The remaining time series analysis and text stream mining includes three phases: (1) bursty words; (2)phase; (3)tweet.
%An accurate recent states learning leads to accurate event detection.
\begin{rmk}[The Set of Events' Candidate Words] 
The set of events' candidate words \(\mathcal{B}_{c,t}\) are defined by the bursty words in recent state \(\bm{r}_{c,t}\).
\end{rmk}

\begin{rmk}[Event Phrase] 
Event phase \(\mathcal{C}_{c,t,i}\) is the \(i\)-th combination of words which occured in the set of events' cadidate words \(\mathcal{B}_{c,t}\), and represents the \(i\)-th event happend in time \(t\) under the category \(c\).
\end{rmk}

\begin{comment}
\begin{rmk}[Event Related Articles] Event related articles \(\mathcal{D}_{c,t,i}\) are articles that relate to the \(i\)-th event in time \(t\) under the category \(c\), and correspond to the event phase \(\mathcal{C}_{c,t,i}\).
\end{rmk}
\end{comment}




\section{Experiments}
\subsection{Effects of History States and Recent States}
In this subsection, we demonstrate the effectiveness of \textit{history states} initialized from knowledge base and \textit{recent states} learned by transfer learning. 

\textbf{Knowledge Base.} 
We construct the taxonomy graph \(G^{(0)}\), the category-page bipartite graph \(G^{(1)}\) from the latest dump of category links\footnote{\url{https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-categorylinks.sql.gz}} and the page-content map \(G^{(2)}\) from Wikipedia pages\footnote{\url{https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2 }}.
We set \(K_{KB}=100\), which means 100 categories are selected manually to cover the topics of Wikipedia and the target corpus as widely as possible. 
There are two kinds of categories are considered. 
The mid-high categories in the taxonomy graph \(G^{(0)'}\), which are representative, are likely to be selected, such as \textit{Aviation}, \textit{Military}, and \textit{Middle East}, etc.
And the mid categories, which reflect the main interests of the target corpus, are also taken into consideration, such as \textit{American Football}, \textit{Basketball}, and \textit{Baseball}, etc. 
%Other knowledge bases which have the above mentioned threefold structure are also available for conducting.

\textbf{Text Stream Dataset.} We conduct the empirical analysis on a text stream benchmark \textit{Edinburgh twitter corpus} which is constructed by \cite{petrovic2012using} and widely used by previous event detection researches \cite{petrovic2013can} \cite{Wurzer:2015wq}. 
Due to the developer policy of Twitter, \cite{petrovic2012using} only redistributes tweets' IDs\footnote{\url{http://demeter.inf.ed.ac.uk/cross/docs/fsd_corpus.tar.gz}}.
%\footnote{\url{https://dev.twitter.com/overview/terms/policy}}
We collected the tweets' contents according to the IDs with the help of Twitter API. 
Though we cannot get the whole dataset due to the limit of Twitter API, after neccessary pre-processing, our rebuilt dataset still contains 36,627,434 tweets, which spans identically from 2011/06/30 to 2011/09/15.
More details of the original dataset are described in \cite{petrovic2010edinburgh}.

\textbf{History States and Recent States.} 
The history states are initialized on the pre-defined categories on the knowledge base as Algorithm \ref{alg:normalStatesInit}.
For \textsc{HS-Prior-LDA}, \(K\) is set to be 200, which means \textsc{HS-Prior-LDA} learned 100 history-state-like topics and 100 other topics.
After cross-validated grid-search, \(\lambda\) is set to be 12.8. The other parameters are set as \(\alpha=0.1\), \(\beta=0.005\).
We run \textsc{HS-Prior-LDA} window by window on text stream, and learn specific categories' recent states.
%This process is illustrated by Table \ref{tbl:historyStates}. 

We compare the topic coherence of history states with the topics learned from Wikipedia by LDA in terms of NPMI\cite{Rder2015ExploringTS}.
Different from traditional experiments that only compute the topic coherence of top words, we want to check whether  it can hold for more words.
Due to the limit of NPMI computing module\footnote{\url{https://github.com/AKSW/Palmetto}}, which computes the coherence of up to 10 words each time, we compute NPMI on the combination of top five words and each next five words as Table \ref{tbl:NPMIDetails}.

%如图（topic）中，能够从Military*中学习出tweet（20110728）话题中包含libyan。


%We use 20newsgroups\cite{lang1995newsweeder} dataset\footnote{\url{http://qwone.com/~jason/20Newsgroups}} to check the effects of normal states initialization.


\begin{comment}
\begin{table}[]
\scriptsize
\centering
\caption{Normal State's cateogries corresponding to the 20-newsgroups corpus, and the F1 score on the classification task}
\label{my-label}
\begin{tabular}{|l|l|}
\hline
comp.graphics            & Computer graphics      \\ \hline
comp.os.ms-windows.misc  & Microsoft Windows      \\ \hline
comp.sys.ibm.pc.hardware & IBM personal computers \\ \hline
comp.sys.mac.hardware    & Macintosh computers    \\ \hline
comp.windows.x           & X Window System        \\ \hline
rec.autos                & Automobiles            \\ \hline
rec.motorcycles          & Motorcycles            \\ \hline
rec.sport.baseball       & Baseball               \\ \hline
rec.sport.hockey         & Hockey                 \\ \hline
sci.crypt                & Cryptography           \\ \hline
sci.electronics          & Electronics            \\ \hline
sci.med                  & Medicine               \\ \hline
sci.space                & Outer space            \\ \hline
misc.forsale             & Sales                  \\ \hline
talk.politics.misc       & Politics               \\ \hline
talk.politics.guns       & Gun politics          \\ \hline
talk.politics.mideast    & Middle East           \\ \hline
talk.religion.misc       & Religion               \\ \hline
alt.atheism              & Atheism                \\ \hline
soc.religion.christian   & Christians             \\ \Xhline{3\arrayrulewidth}
LDA & 0.74\\ \hline
BOW & 0.84\\ \hline
doc2vec & 0.73\\ \hline
NS-Prior-LDA & 0.89\\ \hline
\end{tabular}
\end{table}
\end{comment}

\begin{comment}
\begin{table}[]
\tiny
\centering
\caption{My caption}
\label{my-label}
\begin{tabular}{|l|l|l|l|l|}
\hline
 &  & LDA & BOW  & \begin{tabular}[c]{@{}l@{}}NS-Prior-\\ LDA\end{tabular} \\ \hline
comp.graphics & Computer graphics &  &  &    \\ \hline
comp.os.ms-windows.misc & Microsoft Windows &  &  &    \\ \hline
comp.sys.ibm.pc.hardware & IBM personal computers &  &  &    \\ \hline
comp.sys.mac.hardware & Macintosh computers &  &  &    \\ \hline
comp.windows.x & X Window System &  &  &    \\ \hline
rec.autos & Automobiles &  &  &    \\ \hline
rec.motorcycles & Motorcycles &  &  &    \\ \hline
rec.sport.baseball & Baseball &  &  &    \\ \hline
rec.sport.hockey & Hockey &  &  &    \\ \hline
sci.crypt & Cryptography &  &  &    \\ \hline
sci.electronics & Electronics &  &  &    \\ \hline
sci.med & Medicine &  &  &    \\ \hline
sci.space & Outer space &  &  &    \\ \hline
misc.forsale & Sales &  &  &    \\ \hline
talk.politics.misc & Politics &  &  &    \\ \hline
talk.politics.guns & Gun politics &  &  &    \\ \hline
talk.politics.mideast & Middle East &  &  &   \\ \hline
talk.religion.misc & Religion &  &  &    \\ \hline
alt.atheism & Atheism &  &  &    \\ \hline
soc.religion.christian & Christians &  &   &  \\ \hline
In total &  &  &  & \\ \hline
\end{tabular}
\end{table}
\end{comment}

\begin{comment}
\begin{figure}
        \centering
        \includegraphics[height=4.0cm]{img/pmi.pdf}
        \caption{The quality of all twitter topics learned by NS-Prior-LDA increases with normal states weight (\(\lambda\)) before \(\lambda=12.8\). The optimized PMI is gained with moderate normal states weight when considering topics \(k\leq K_{\bm{KB}}\) and topics \(k > K_{\bm{KB}}\) together.}
\end{figure}
\end{comment}

\begin{table}[]
\centering
\scalebox{0.76}{
\begin{tabular}{|c|c|l|c|}
\hline
\#group* & \#word*  & words & NPMI\\ \hline
0 & 6-10 & airlines aviation flying pilot squadron &  0.113\\ \hline
1 & 11-15 &flights pilots raf airways fighter & 0.155\\ \hline
2 & 16-20 &boeing runway force crashed flew   & 0.092\\ \hline
3 & 21-25 &airfield landing passengers plane aerial & 0.179\\ \hline
4 & 26-30 &bomber radar wing bombers crash & 0.137\\ \hline
5 & 31-35 &airbus airports operations jet helicopter & 0.189\\ \hline
6 & 36-40 &squadrons base flown havilland crew & 0.088\\ \hline
7 & 41-45 &combat luftwaffe aerodrome carrier fokker & 0.159\\ \hline
8 & 46-50 &planes fly engine takeoff fleet & 0.186\\ \hline
9 & 51-55 &fuselage helicopters aviator naval aero & 0.157\\ \hline
10 & 56-60 &glider command training balloon faa & 0.166\\ \hline
\(\cdots\) & \(\cdots\) &\(\cdots\) &\(\cdots\)\\ \hline
18 & 96-100 &scheduled carriers military curtiss biplane &0.131\\ \hline
19 & 101-105 &accident engines iaf albatross rcaf &0.068\\ \hline
\end{tabular}
}
\caption{Top words' topic coherence of \textit{Aviation}'s history state. * means the group also contains the five top words \textit{aircraft}, \textit{air}, \textit{airport}, \textit{flight}, and \textit{airline}, but we don't show them in table to save space. NPMI is computed on ten words (a combination of words in each row and the five top words).}
\label{tbl:NPMIDetails}
\end{table}


\begin{figure}
        \centering
        \includegraphics[width=1.0\columnwidth]{img/NPMI.pdf}
        \caption{Effectiveness of history state in terms of NPMI}
        \label{fig:NPMI}
\end{figure}


\begin{comment}
\begin{table}
\centering
\caption{The PMI of twitter topics learned by NS-Prior-LDA, its variant, and other baselines}
    \begin{tabular}{|l|l|c|}
    \hline
    Model & Prior Knowledge & PMI \\ \hline
    LDA & None  & 1.265 \(\pm\) 0.013     \\ \hline
    BurstyBTM\cite{Yan:2015wm} & None    & 1.467 \(\pm\) 0.017     \\ \hline
    NS-Prior-LDA\(^{(-)}\)   &   \begin{tabular}[c]{@{}l@{}}\footnotesize{Words in categories simply}\\ \footnotesize{extracted from Wikipedia}\end{tabular} & 1.439 \(\pm\) 0.010     \\ \hline
    NS-Prior-LDA         & \begin{tabular}[c]{@{}l@{}}\footnotesize{Normal states initialized} \\\footnotesize{from wikipedia}\end{tabular} & 1.523 \(\pm\) 0.017     \\ \hline
    \end{tabular}
\label{tbl:NS-Prior-LDA}
\end{table}
\end{comment}

\begin{comment}
\begin{table*}[ht]
\centering
\caption{History States initialized from Wikipedia and topical words learned from HS-Prior-LDA}
\scalebox{0.76}{
\begin{tabular}{|cc|cc|cc|cc|cc|cc|}
\hline
\multicolumn{2}{|c|}{\textit{Aviation}} & \multicolumn{2}{c|}{\textit{Health}} & \multicolumn{2}{c|}{\textit{Middle East}} & \multicolumn{2}{c|}{\textit{Military}} & \multicolumn{2}{c|}{\textit{Mobile Phones}} & \multicolumn{2}{c|}{\textit{Video Games}} \\
\begin{tabular}[c]{@{}c@{}}Normal\\ States\end{tabular} & \begin{tabular}[c]{@{}c@{}}Topical\\ Words\end{tabular} & \begin{tabular}[c]{@{}c@{}}Normal\\ States\end{tabular} & \begin{tabular}[c]{@{}c@{}}Topical\\ Words\end{tabular} & \begin{tabular}[c]{@{}c@{}}Normal\\ States\end{tabular} & \begin{tabular}[c]{@{}c@{}}Topical\\ Words\end{tabular} & \begin{tabular}[c]{@{}c@{}}Normal\\ States\end{tabular} & \begin{tabular}[c]{@{}c@{}}Topical\\ Words\end{tabular} & \begin{tabular}[c]{@{}c@{}}Normal\\ States\end{tabular} & \begin{tabular}[c]{@{}c@{}}Topical\\ Words\end{tabular} & \begin{tabular}[c]{@{}c@{}}Normal\\ States\end{tabular} & \begin{tabular}[c]{@{}c@{}}Topical\\ Words\end{tabular} \\ 
\hline
aircraft & air\scriptsize(3253) & health & weight\scriptsize(16344) & al & \textcolor{red}{\textit{\#syria}}\scriptsize(4212) & army & killed\scriptsize(4055)  & android & iphone\scriptsize (13674) & game & games\scriptsize(8812) \\ 
air & plane & patients & loss & israel & \textcolor{red}{\textit{\#bahrain}} & military & news & mobile & apple & player & liked \\ 
airport & flight & medical & diet & iran & people & air & \textcolor{red}{\textit{\#libya}}\scriptsize(3503) & nokia & android & playstation & free \\ 
flight & time & disease & health & arab & israel & command & libya & ios & app & gameplay & xbox \\
airline & airlines & treatment & cancer & israeli & police & force & rebels & phone & ipad & nintendo & 360 \\
airlines & news & hospital & lose & egypt & \textcolor{red}{\textit{\#libya}}\scriptsize(2557) & regiment & people & samsung & samsung & games & playing \\
aviation & boat & patient & fat & egyptian & \#egypt & forces & police & game & mobile & players & played \\
flying & airport & clinical & tips & ibn & news & squadron & war & app & blackberry & xbox &iphone\scriptsize(2820)\\
pilot & force & symptoms & treatment & jerusalem & \#israel & infantry & libyan & iphone & tablet & mode & time\\
squadron & fly & cancer & body & syria & world & battle & attack & htc & apps & arcade & \textcolor{red}{\textit{ps3}}\\
\hline
\end{tabular}
}
\label{tbl:historyStates}
\end{table*}
\end{comment}


\begin{table*}[ht]
\centering
\caption{Events about \textit{military} detected by systems between 2011-07-22 and 2011-07-28}
\scalebox{0.76}{
\label{my-label}
\begin{tabular}{|l|L{3cm}|l|l|}
\hline
Date & Event key words & Representative event tweet & \begin{tabular}[c]{@{}l@{}}Number of \\ event tweet\end{tabular} \\ \hline
7/22/11 & \begin{tabular}[c]{@{}l@{}}Norway, Oslo,\\ attacks, bombing\end{tabular} & \begin{tabular}[c]{@{}l@{}}Terror Attacks Devastate Norway: A bomb ripped through \\ government offices in Oslo and a gunman...˙http://dlvr.it/cLbk8\end{tabular} & 557 \\ \hline
7/23/11 & Gunman, rink & \begin{tabular}[c]{@{}l@{}}Gunman Kills Self, 5 Others at Texas Roller Rink \\ http://dlvr.it/cLcTH\end{tabular} & 43 \\ \hline
7/26/11 & \begin{tabular}[c]{@{}l@{}}Kandahar, mayor, \\ suicide, attack\end{tabular} & \begin{tabular}[c]{@{}l@{}}TELEGRAPH{]}: Kandahar mayor killed by Afghan suicide \\ bomber: The mayor of Kandahar, the biggest city in south \_\end{tabular} & 25 \\ \hline
7/28/11 & Ft., Hood, attack & Possible Ft. Hood Attack Thwarted http://t.co/BSJ33hk & 20 \\ \hline
7/28/11 & \begin{tabular}[c]{@{}l@{}}Libyan, rebel, \\ gunned\end{tabular} & \begin{tabular}[c]{@{}l@{}}Libyan rebel chief gunned down in Benghazi \\ http://sns.mx/prfvy1\end{tabular} & 44 \\ \hline
\end{tabular}
}
\end{table*}

\begin{comment}
\begin{figure*}
    \label{fig:algorithm}
    \includegraphics[width=1.0\textwidth]{img/screenShot.png}
    \caption{An illustration of the time series of Military related states on Twitter dataset from 2011-06-30 to 2011-09-15.}
\end{figure*}
\end{comment}

\subsection{Effects of Event Detection}
\textbf{Baselines Methods.} We compare our proposed method against the following methods, Twevent\cite{Twevent2012}, BurstyBTM\cite{Yan:2015wm}, LSH\cite{Petrovic:2010uj}, EDCoW \cite{Weng:2011wz}, TimeUserLDA\cite{Diao:2012wj}, and UMass System\cite{Allan:2000wu}.
We implement these competing methods based on the open source community versions, e.g. EDCoW\footnote{\url{https://github.com/Falitokiniaina/EDCoW}}, or the authors' releases, e.g. BurstyBTM\footnote{\url{https://github.com/xiaohuiyan/BurstyBTM}}.
These methods work in four ways. 
1) Based on topic model, BurstyBTM and TimeUserLDA detect bursty topics. 
Although they are desinged for batch learning initially, we run them on the slide windows to adapt to the text stream environment.
2) Integrated with knowledge base, Twevent detects bursty segments, groups them into clusters, and then filters out the meaningless ones by Wikipedia.
3) By clustering articles, UMass System and LSH decide whether the article belongs to the existing event or a new one.
As designed for First Story Detection task (one of the Topic Detection and Tracking subtasks\cite{allan2012topic}) initially, they prefer to enlarge the recall of detected events. 
4) By analyzing word frequencies, EDCoW clusters the bursty words into events.

\textbf{Evaluation Metrics.} 
The first benchmark on \textit{Edinburgh twitter corpus} contains 27 manually labeled events\cite{petrovic2013can}\footnote{\url{http://demeter.inf.ed.ac.uk/cross/docs/Newswire_Events.tar.gz}}, which all exist in our rebuilt dataset on the \textit{Edinburgh twitter}'s IDs.
These labeled events focus on the events that are both mentioned in twitter and newswire,e.g. \textit{``Oslo Attacks"} and \textit{``US Increasing Debt Ceiling"}, but still miss many important events such as \textit{``Hurricane Irene"}, \textit{``Al-Qaida's No. 2 Leader Being Killed"}, and popular events such as \textit{``Harry Potter and the Deathly Hallows (Part 2)"}.
To enlarge the ground truth of realistic events, we manually evaluate the candidate events detected by LTDetector, Twevent, EDCoW, BurstyBTM, and TimeUserLDA, and  use the labeled events as the second benchmark.
We use precision and recall to evaluate each method on both benchmarks.
\begin{table}[h]
\scriptsize
\centering
\scalebox{0.95}{
    \begin{tabular}{|l|l|l|l|l|}
    \hline
    Method & \begin{tabular}[c]{@{}l@{}}Recall@ \\ Benchmark1\end{tabular} & \begin{tabular}[c]{@{}l@{}}Precision@ \\ Benchmark2\end{tabular} & \begin{tabular}[c]{@{}l@{}}Recall@ \\ Benchmark2\end{tabular} & \begin{tabular}[c]{@{}l@{}}DERate\\(Duplicate \\ Event Rate)\end{tabular} \\ \hline
    UMass System & 0.882 & 0.138 & 0.941 & 0.071 \\ \hline
    LSH & 0.824 & 0.095 & 0.803 & 0.302 \\ \hline
    TimeUserLDA & 0.353 & 0.536 & 0.071 & 0.054 \\ \hline
    Twevent & 0.824 & 0.697 & 0.641 & 0.113 \\ \hline
    EDCoW & 0.412 & 0.756 & 0.119 & 0.290 \\ \hline
    BurstyBTM & 0.647 & 0.809 & 0.170 & 0.045 \\ \hline
    \textsc{NSDetector} & 1.000 & 0.894 & 0.950 & 0.042 \\ \hline
    \end{tabular}
}
\caption{Overall Performance on Event Detection}
\end{table}

\textbf{Overall Performances.}
Table 1 reports the number of events
detected, the precision and recall, of the three methods respectively.
The results of EDCoW are reproduced from [21]9
. Shown in the
table, our proposed method Twevent yields the best precision of
86.1\% which is significantly larger than the precisions achieved
by EDCoW and Tweventu. Observe that our method Twevent detects
101 events with a recall of 75 realistic events. On the same
dataset, EDCoW detects 21 events in total with 13 realistic events.
Tweventu yields a slighter worse precision than EDCoW (75.3%
vs 76.2\%) but detects the largest number of realistic events. In
terms of DERate, Twevent achieves the lowest rate despite that our
method detects much more events than EDCoW (101 vs 21). On
the other hand, we observe that Tweventu delivers the worst DERate,
more than double of Twevent (41\% vs 16.0\%). That is, the unigrams
about the same event are clustered into two or more events.
Because a tweet segment usually conveys very specific information,
the tweets containing the tweet segment are all about the same
topic (e.g., the event). Two tweet segments about the same event
are therefore have higher chance to be clustered together.


\begin{comment}
20-newsgroup\footnote{http://qwone.com/~jason/20Newsgroups/}

NPMI\cite{Aletras2013EvaluatingTC}\cite{Rder2015ExploringTS}\footnote{https://github.com/AKSW/Palmetto}.
\end{comment}
%\textbf{Topic Coherence} \cite{roder2015exploring}
%\textbf{PMI}
%\subsection{Evaluation of Detected Events}
\begin{comment}
\textbf{Precision} Precision@Benchmark1, Precision@Benchmark2

\textbf{Recall}

\textbf{Accuracy}

\textbf{DERate(Duplicate Event Rate)}
\end{comment}
%\subsection{Case Study}


%\subsection{Application on Reddit}

\section{Conclusions \& Future Work}
Knowledge base is constructed elaborately and contains rich information, which can benefit the not-well-organized text stream. As a part of our future work, we will explore the effects of transfer learning from knowledge base to text stream for more tasks, such as text classification and key words extraction, especially for short texts. 
%Another work what we are interested in is to utilize the knowledge base Microsoft Academic Graph, which also contains the taxonomy structure and text contents, to mine the research topics and trends from arXiv stream in fine grain. 

\begin{comment}
Twitter, as a new type of social media, has experienced an explosive growth in terms of both users and information volume in recent years. 
The characteristics of tweets propose severe challenges to many tasks including event detection. 
In this paper, we present a novel event detection system for Twitter stream, called Twevent, to tackle the adverse impacts of tweets: short and noisy content, diverse and dynamic topics, and large data volume. 
One of the key concept in Twevent is to use tweet segment instead of unigram for identifying the bursty features and then distinguishing the realistic events from the noisy ones. 
Twevent demonstrates outstanding performance in our experiments: effectiveness, informativeness, and efficiency. 
As a part of our future work, we will investigate the effectiveness of utilizing more features from tweets (e.g., retweet rate and hashtags) in Twevent. 
Another important task is to investigate the effectiveness of Twevent when none of the segments of an event is covered by Wikipedia.
\end{comment}

\newpage
\bibliographystyle{named}
\small
\bibliography{paperbib}


\end{document}
